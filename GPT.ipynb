{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Requisite"
      ],
      "metadata": {
        "id": "m8XFZUG8DlC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l4mlQqfcC4P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH4jCbovq7eG",
        "outputId": "dca8fd1c-6271-4853-a5a8-0be954f33850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "!python -m spacy download de_core_news_sm -q # Specific tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wxss6RC50U0"
      },
      "source": [
        "# Data Preprocessing and Visualization\n",
        "Dataset is imported from torchtext (Multi30K)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.17.0 -q\n",
        "!pip install 'portalocker>=2.0.0' -q # Required libraries. If throwing error even after install, restart the session (Libraries are kept even after restart).\n",
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "# Importing the dataset\n",
        "\n",
        "batch_size=32\n",
        "\n",
        "train_iter, val_iter = Multi30k(split=('train', 'valid'), language_pair=('de', 'en'))# Dataset\n",
        "from torchtext.data.functional import to_map_style_dataset # Map style gives no warning messages.\n",
        "train_iter, val_iter= to_map_style_dataset(train_iter), to_map_style_dataset(val_iter)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZekPxywVEQIe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Visualization"
      ],
      "metadata": {
        "id": "llkirQONHR-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m04EkfWzNhC",
        "outputId": "0680b7f5-b7a6-42f1-b825-8025821c839a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of datapoints in train set: 1772238,Number of datapoints in train set:62283\n",
            "number of english characters:80,number of german characters:99\n"
          ]
        }
      ],
      "source": [
        "# Number of datapoints\n",
        "\n",
        "def get_size(iter):\n",
        "  return  sum([len(z) for i,z in iter])\n",
        "\n",
        "print(f'Number of datapoints in train set: {get_size(train_iter)},Number of datapoints in train set:{get_size(val_iter)}')\n",
        "\n",
        "# Number of characters\n",
        "\n",
        "def chars(iter):\n",
        "  char_en=[]\n",
        "  char_de=[]\n",
        "  return set(k for i, z in iter for j in i for k in j),set(k for i, z in iter for j in z for k in j)\n",
        "\n",
        "char_de,char_en= chars(train_iter+ val_iter)\n",
        "print(f'number of english characters:{len(char_en)},number of german characters:{len(char_de)}')\n",
        "\n",
        "\n",
        "# Frequency of characters\n",
        "\n",
        "def chars(iter):\n",
        "  char_en={}\n",
        "  char_de={}\n",
        "  for i,z in iter:\n",
        "    idx1=[k for j in i for k in j]\n",
        "    idx2=[k for j in z  for k in j ]\n",
        "    for i in idx1:\n",
        "      char_de[i]=char_de.get(i,0)+1\n",
        "    for i in idx2:\n",
        "      char_en[i]=char_en.get(i,0)+1\n",
        "  return char_en, char_de\n",
        "\n",
        "# chars(train_iter+val_iter) # Run this to take a look a the chars and their frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check wordwise"
      ],
      "metadata": {
        "id": "GfyAjyvkMVfg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEwwThrK4kVG",
        "outputId": "e0e31fdb-c15c-4097-90d8-3ec33d75d85e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of english words:24889,number of german words:15456\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Ein', 13901),\n",
              "  ('einem', 13697),\n",
              "  ('in', 11829),\n",
              "  ('und', 8925),\n",
              "  ('mit', 8816),\n",
              "  ('auf', 8409),\n",
              "  ('Mann', 7433),\n",
              "  ('einer', 6747),\n",
              "  ('Eine', 5932),\n",
              "  ('ein', 4852),\n",
              "  ('der', 4497),\n",
              "  ('eine', 3972),\n",
              "  ('Frau', 3895),\n",
              "  ('die', 3606),\n",
              "  ('einen', 3479),\n",
              "  ('Zwei', 3175),\n",
              "  ('im', 3079),\n",
              "  ('an', 2569),\n",
              "  ('von', 2360),\n",
              "  ('dem', 2132)],\n",
              " [('a', 31704),\n",
              "  ('A', 17457),\n",
              "  ('in', 14830),\n",
              "  ('the', 9922),\n",
              "  ('on', 7810),\n",
              "  ('is', 7521),\n",
              "  ('and', 7375),\n",
              "  ('man', 7165),\n",
              "  ('of', 6859),\n",
              "  ('with', 6171),\n",
              "  ('are', 3714),\n",
              "  ('woman', 3652),\n",
              "  ('to', 3123),\n",
              "  ('Two', 3116),\n",
              "  ('at', 2905),\n",
              "  ('wearing', 2616),\n",
              "  ('people', 2348),\n",
              "  ('white', 2104),\n",
              "  ('young', 2055),\n",
              "  ('his', 1969)])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "def vocab(iter):\n",
        "    vocab_en = {}\n",
        "    vocab_de = {}\n",
        "\n",
        "    for en_sentence, de_sentence in iter:\n",
        "        # Process the German sentence\n",
        "        for word in de_sentence.split():\n",
        "            vocab_de[word] = vocab_de.get(word, 0) + 1\n",
        "\n",
        "        # Process the English sentence\n",
        "        for word in en_sentence.split():\n",
        "            vocab_en[word] = vocab_en.get(word, 0) + 1\n",
        "\n",
        "    # Sort the vocabularies by frequency\n",
        "    sorted_vocab_en = sorted(vocab_en.items(), key=lambda x: -x[1])\n",
        "    sorted_vocab_de = sorted(vocab_de.items(), key=lambda x: -x[1])\n",
        "\n",
        "    return sorted_vocab_en, sorted_vocab_de\n",
        "\n",
        "vocab_en,vocab_de= vocab(train_iter)\n",
        "# clear_output\n",
        "print(f'number of english words:{len(vocab_en)},number of german words:{len(vocab_de)}')\n",
        "vocab_en[:20],vocab_de[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing is done with spacy. We add token [\"\\<bos>\"] at the beginning of the sentence and [\"\\<eos>\"] at the end."
      ],
      "metadata": {
        "id": "b-sVXtyVcQy4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikyH_Dro8WU5"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jLu4utDaplR"
      },
      "outputs": [],
      "source": [
        "max_length=80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWNTei4sUNvf"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "import spacy\n",
        "\n",
        "\n",
        "# Load Spacy tokenizers\n",
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "# Separate yield_tokens functions for German (source) and English (target)\n",
        "def yield_tokens(data_iter, tokenizer, is_source=True):\n",
        "    for src, tgt in data_iter:\n",
        "        if is_source:\n",
        "            yield tokenizer(src)  # German (source)\n",
        "        else:\n",
        "            yield tokenizer(tgt)  # English (target)\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def preprocess_sentence(sentence, vocab, tokenizer):\n",
        "    tokens = tokenizer(sentence)\n",
        "    tokens = [vocab['<bos>']] + [vocab[token] for token in tokens] + [vocab['<eos>']]\n",
        "    if len(tokens) > max_length:\n",
        "      tokens = tokens[:max_length-1] + [vocab['<eos>']]\n",
        "    else:\n",
        "      tokens += [vocab['<pad>']] * (max_length - len(tokens))\n",
        "    return torch.tensor(tokens, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "      src_batch.append(preprocess_sentence(src_sample, vocab_de, tokenize_de))\n",
        "      tgt_batch.append(preprocess_sentence(tgt_sample, vocab_en, tokenize_en))\n",
        "    src_batch = torch.stack(src_batch)\n",
        "    tgt_batch = torch.stack(tgt_batch)\n",
        "    return src_batch, tgt_batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tvMYXT2YDi9"
      },
      "outputs": [],
      "source": [
        "# Build vocabularies for German (source) and English (target)\n",
        "vocab_de = build_vocab_from_iterator(yield_tokens(train_iter, tokenize_de, is_source=True), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "vocab_en = build_vocab_from_iterator(yield_tokens(train_iter, tokenize_en, is_source=False), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "\n",
        "# Set default index to handle unknown tokens\n",
        "vocab_de.set_default_index(vocab_de[\"<unk>\"])\n",
        "vocab_en.set_default_index(vocab_en[\"<unk>\"])\n",
        "\n",
        "bos_idx = vocab_de[\"<bos>\"]\n",
        "eos_idx = vocab_de[\"<eos>\"]\n",
        "pad_idx = vocab_de[\"<pad>\"]\n",
        "\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(list(train_iter), batch_size=32, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(list(val_iter), batch_size=32, collate_fn=collate_fn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAHFNX3Rx65T"
      },
      "source": [
        "# GPT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1llEzjdy0GZQ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W60KdCuO0I0M"
      },
      "outputs": [],
      "source": [
        "n_embd=512\n",
        "n_head= 8\n",
        "n_layers= 6\n",
        "dropout= 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VW2KcKQev2H"
      },
      "outputs": [],
      "source": [
        "class maskless_head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.head_size= head_size\n",
        "    self.key=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.query=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.value=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.softmax=nn.Softmax(dim=-1)\n",
        "    self.dropout= nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    k=self.key(x) # b,T,N\n",
        "    q=self.query(x) # b,T,N\n",
        "    v=self.value(x) # b,T,N\n",
        "    k = k.transpose(-2, -1)  # b,N,T\n",
        "    wei= q @ k * self.head_size**-0.5 # b,T,T\n",
        "    wei=self.softmax(wei)\n",
        "    wei = self.dropout(wei)\n",
        "    return wei @ v # b,T,N\n",
        "\n",
        "class masked_head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(max_length, max_length)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class maskless_cross_head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.head_size= head_size\n",
        "    self.key=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.query=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.value=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.softmax=nn.Softmax(dim=-1)\n",
        "    self.dropout= nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x,y):\n",
        "    k=self.key(y) # b,T,N\n",
        "    q=self.query(x) # b,T,N\n",
        "    v=self.value(y) # b,T,N\n",
        "    k = k.transpose(-2, -1) * self.head_size**-0.5 # b,N,T\n",
        "    wei= q @ k # b,T,T\n",
        "    wei=self.softmax(wei)\n",
        "    wei = self.dropout(wei)\n",
        "    return wei @ v # b,T,N\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, n_embd):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "    nn.Linear(n_embd, 4 * n_embd),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4 * n_embd, n_embd),\n",
        "    nn.Dropout(dropout),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTGi9-tO3pTl"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, head_size, masked='True'):\n",
        "    super().__init__()\n",
        "    if masked=='True':\n",
        "      self.heads = nn.ModuleList([masked_head(head_size) for _ in range(num_heads)])\n",
        "    elif masked=='cross':\n",
        "      self.heads = nn.ModuleList([maskless_cross_head(head_size) for _ in range(num_heads)])\n",
        "    else:\n",
        "      self.heads = nn.ModuleList([maskless_head(head_size) for _ in range(num_heads)])\n",
        "    self.proj = nn.Linear(n_embd, n_embd)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x,y=None):\n",
        "    if y is not None:\n",
        "      out = torch.cat([h(x,y) for h in self.heads], dim=-1)\n",
        "    else:\n",
        "      out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVYhIBeK2dl8"
      },
      "outputs": [],
      "source": [
        "class encoder_block(nn.Module):\n",
        "  def __init__(self, n_embd, n_head):\n",
        "    # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "    super().__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size,masked='False')\n",
        "    self.ffwd = FeedForward(n_embd)\n",
        "    self.ln1 = nn.LayerNorm(n_embd)\n",
        "    self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x\n",
        "\n",
        "class decoder_block(nn.Module):\n",
        "  def __init__(self, n_embd, n_head):\n",
        "    # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "    super().__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size,masked='False')\n",
        "    self.ca = MultiHeadAttention(n_head, head_size,masked='cross')\n",
        "    self.ffwd = FeedForward(n_embd)\n",
        "    self.ln1 = nn.LayerNorm(n_embd)\n",
        "    self.ln2 = nn.LayerNorm(n_embd)\n",
        "    self.ln3 = nn.LayerNorm(n_embd)\n",
        "  def forward(self, x,encoder_output):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x=  x + self.ca(self.ln2(x),encoder_output)\n",
        "    x = x + self.ffwd(self.ln3(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBiQNYNBu11E"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, model_dimension, dropout_probability, expected_max_sequence_length=max_length):\n",
        "      super().__init__()\n",
        "      self.dropout = nn.Dropout(p=dropout_probability)\n",
        "      position_id = torch.arange(0, expected_max_sequence_length).unsqueeze(1)\n",
        "      frequencies = torch.pow(10000., -torch.arange(0, model_dimension, 2, dtype=torch.float) / model_dimension)\n",
        "\n",
        "      positional_encodings_table = torch.zeros(expected_max_sequence_length, model_dimension)\n",
        "      positional_encodings_table[:, 0::2] = torch.sin(position_id * frequencies)  # sine on even positions\n",
        "      positional_encodings_table[:, 1::2] = torch.cos(position_id * frequencies)  # cosine on odd positions\n",
        "      self.register_buffer('positional_encodings_table', positional_encodings_table)\n",
        "\n",
        "  def forward(self, embeddings_batch):\n",
        "      assert embeddings_batch.ndim == 3 and embeddings_batch.shape[-1] == self.positional_encodings_table.shape[1], \\\n",
        "          f'Expected (batch size, max token sequence length, model dimension) got {embeddings_batch.shape}'\n",
        "\n",
        "      positional_encodings = self.positional_encodings_table[:embeddings_batch.shape[1]]\n",
        "      return self.dropout(embeddings_batch + positional_encodings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJCVtwCPwirJ"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, n_embd, n_head, n_layers, max_length, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.encoding= nn.Embedding(len(vocab_de),n_embd)\n",
        "    self.decoding= nn.Embedding(len(vocab_en),n_embd)\n",
        "    self.encoder = nn.ModuleList([encoder_block(n_embd, n_head) for _ in range(n_layers)])\n",
        "    self.decoder = nn.ModuleList([decoder_block(n_embd, n_head) for _ in range(n_layers)])\n",
        "    self.src_pos_embedding = PositionalEncoding(n_embd, dropout)\n",
        "    self.trg_pos_embedding = PositionalEncoding(n_embd, dropout)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc_out = nn.Linear(n_embd, len(vocab_en))\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "    self.init_weights()\n",
        "  def init_weights(self):\n",
        "    for p in self.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    x = self.encoding(x)\n",
        "    y = self.decoding(y)\n",
        "    x = self.src_pos_embedding(x)\n",
        "    y = self.trg_pos_embedding(y)\n",
        "\n",
        "    for enc_block in self.encoder:\n",
        "        x = enc_block(x)\n",
        "    # Decoder\n",
        "    for dec_block in self.decoder:\n",
        "        y = dec_block(y, x)\n",
        "\n",
        "    # Final linear layer\n",
        "    out = self.fc_out(y)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcrwWGMVfe77"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZaFnqjUjnEH"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model= Transformer(n_embd,n_head,n_layers,max_length)\n",
        "model.to(device)\n",
        "optimizer= torch.optim.Adam(model.parameters(),lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPJxtBLgS8Jv"
      },
      "outputs": [],
      "source": [
        "loss_fn  = torch.nn.CrossEntropyLoss()\n",
        "epochs=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjwUDth-g_UX"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/model_checkpoints'\n",
        "checkpoint_file = f'{save_path}/model_checkpoint.pt'\n",
        "if os.path.exists(checkpoint_file):\n",
        "  os.remove(checkpoint_file)\n",
        "torch.save(model.state_dict(), checkpoint_file)\n",
        "for epoch in range(epochs):\n",
        "  model.train()  # Set model to training mode\n",
        "  total_loss = 0\n",
        "  for batch, (src, tgt) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    src, tgt = src.to(device), tgt.to(device)  # Move data to GPU if available\n",
        "\n",
        "    # Forward pass through the model\n",
        "    logits = model(src, tgt)\n",
        "    logits = logits.view(-1, logits.size(-1))\n",
        "\n",
        "    # Flatten target to [batch_size * sequence_length]\n",
        "    tgt = tgt.view(-1)\n",
        "\n",
        "    loss = loss_fn(logits, tgt)\n",
        "\n",
        "    # Backpropagation and optimization step\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "    loss.backward()        # Compute gradients\n",
        "    optimizer.step()       # Update weights\n",
        "\n",
        "    # Accumulate total loss for reporting\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    # Epoch-level reporting\n",
        "    print(f'Epoch {epoch+1}: Batch= {batch} Loss: {(loss.item()):.4f}')\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  print(f'Epoch {epoch+1}: Loss: {avg_loss:.4f}')\n",
        "  if os.path.exists(checkpoint_file):\n",
        "    os.remove(checkpoint_file)\n",
        "  torch.save(model.state_dict(), checkpoint_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0cwFlkgyCrj"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqdHFt6oG3ls",
        "outputId": "e0a65d41-1fed-4d3f-b977-e0b6853b9c26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_path = '/content/drive/MyDrive/model_checkpoints'\n",
        "checkpoint_file = f'{save_path}/model_checkpoint.pt'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model= Transformer(n_embd,n_head,n_layers,max_length)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(checkpoint_file,map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx-3JbU10sLH"
      },
      "outputs": [],
      "source": [
        "k='Hey Alter, wie geht es dir? '\n",
        "k=preprocess_sentence(k, vocab_de, tokenize_de).unsqueeze(0).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOyQPiZw1zqF"
      },
      "outputs": [],
      "source": [
        "start_token=vocab_de[\"<bos>\"]\n",
        "end_token = vocab_de[\"<eos>\"]\n",
        "def generate(model, src, start_token, max_len, device):\n",
        "    model.eval()\n",
        "    src = src.to(device)\n",
        "    target = torch.tensor([[start_token]], device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for _ in range(max_len):\n",
        "        # Pass the source and current target through the model\n",
        "        logits = model(src, target)\n",
        "        # Get the predicted next token (highest probability)\n",
        "        next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "\n",
        "        # Append the predicted token to the target sequence\n",
        "        target = torch.cat([target, next_token], dim=1)\n",
        "\n",
        "        # Stop if end token is generated\n",
        "        if next_token.item() == end_token:\n",
        "          break\n",
        "    return target\n",
        "\n",
        "target_sequence = generate(model, k, start_token, max_length, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U22xxnxyAYS"
      },
      "outputs": [],
      "source": [
        "with model.eval():  # Set model to training mode\n",
        "  total_loss = 0\n",
        "  for batch, (src, tgt) in enumerate(valid_loader):\n",
        "    optimizer.zero_grad()\n",
        "    src, tgt = src.to(device), tgt.to(device)  # Move data to GPU if available\n",
        "\n",
        "    # Forward pass through the model\n",
        "    logits = model(src, tgt)\n",
        "    logits = logits.view(-1, logits.size(-1))\n",
        "\n",
        "    # Flatten target to [batch_size * sequence_length]\n",
        "    tgt = tgt.view(-1)\n",
        "\n",
        "    loss = loss_fn(logits, tgt)\n",
        "\n",
        "    # Accumulate total loss for reporting\n",
        "    total_loss += loss.item()\n",
        "    # Epoch-level reporting\n",
        "    print(f' Batch= {batch} Loss: {(loss.item()):.4f}')\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  print(f'Total Avg_loss =Loss: {avg_loss:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}