{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Requisite"
      ],
      "metadata": {
        "id": "m8XFZUG8DlC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_l4mlQqfcC4P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH4jCbovq7eG",
        "outputId": "ff3c4ecd-bda4-402d-a2b4-2c4edd52708e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "!python -m spacy download de_core_news_sm -q # Specific tokenizer\n",
        "!pip install torchtext==0.17.0 -q\n",
        "!pip install 'portalocker>=2.0.0' -q # Required libraries. If throwing error even after install, restart the session (Libraries are kept even after restart)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wxss6RC50U0"
      },
      "source": [
        "# Data Preprocessing\n",
        "Dataset is imported from torchtext (Multi30K)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import Multi30k"
      ],
      "metadata": {
        "id": "ZekPxywVEQIe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dataset"
      ],
      "metadata": {
        "id": "YCQlHY8ZGrzr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OA8_ezOvPb0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "yMAPtEut1Utl"
      },
      "outputs": [],
      "source": [
        "max_length=80 # The number of\n",
        "batch_size=32\n",
        "\n",
        "train_iter, valid_iter, test_iter = Multi30k(split=('train', 'valid', 'test'), language_pair=('de', 'en'))# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset into dataloader"
      ],
      "metadata": {
        "id": "YDI5eW82GtqQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "JjvGsq4RmwI9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader as Dataloader\n",
        "train_data, val_data = Dataloader(list(train_iter),batch_size=batch_size), Dataloader(list(valid_iter),batch_size=batch_size) #Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check for the number of datapoints"
      ],
      "metadata": {
        "id": "llkirQONHR-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5m04EkfWzNhC",
        "outputId": "63340b7c-f6b6-4fe5-bdc8-dad40b171f7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Number of datapoints in train set: 29001,Number of datapoints in train set:1015'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "def get_size(iter):\n",
        "  return  sum([len(z) for i,z in iter])\n",
        "\n",
        "f'Number of datapoints in train set: {get_size(train_data)},Number of datapoints in train set:{get_size(val_data)}'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the number of chars"
      ],
      "metadata": {
        "id": "mwpbt_1CNo-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chars(iter):\n",
        "  char_en=[]\n",
        "  char_de=[]\n",
        "  return set(k for i, z in iter for j in i for k in j),set(k for i, z in iter for j in z for k in j)\n",
        "\n",
        "char_de,char_en= chars(train_data)\n",
        "print(f'number of english characters:{len(char_en)},number of german characters:{len(char_de)}')"
      ],
      "metadata": {
        "id": "qB1OhMLgKJTR",
        "outputId": "ddc766fe-0ab8-4106-9411-603349b755fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of english characters:80,number of german characters:99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to check how many times a character appears."
      ],
      "metadata": {
        "id": "o-4DiE7uMQfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ChwePu_s2zyD"
      },
      "outputs": [],
      "source": [
        "# def chars(iter):\n",
        "#   char_en={}\n",
        "#   char_de={}\n",
        "#   for i,z in iter:\n",
        "#     idx1=[k for j in i for k in j]\n",
        "#     idx2=[k for j in z  for k in j ]\n",
        "#     for i in idx1:\n",
        "#       char_de[i]=char_de.get(i,0)+1\n",
        "#     for i in idx2:\n",
        "#       char_en[i]=char_en.get(i,0)+1\n",
        "#   return char_en, char_de"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check wordwise"
      ],
      "metadata": {
        "id": "GfyAjyvkMVfg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEwwThrK4kVG",
        "outputId": "a2894565-2d7f-4edb-9007-abb5d381e946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of english words:15456,number of german words:24889\n"
          ]
        }
      ],
      "source": [
        "def vocab(iter):\n",
        "  vocab_en={}\n",
        "  vocab_de={}\n",
        "  for i,z in iter:\n",
        "    for j in i:\n",
        "      idx1=j.split()\n",
        "      for k in idx1:\n",
        "        vocab_de[k]=vocab_de.get(k,0)+1\n",
        "    for j in z:\n",
        "      idx2=j.split()\n",
        "      for k in idx2:\n",
        "        vocab_en[k]=vocab_en.get(k,0)+1\n",
        "\n",
        "  return sorted(vocab_en.items(),key=lambda x:-x[1]),sorted(vocab_de.items(),key=lambda x:-x[1])\n",
        "vocab_en,vocab_de= vocab(train_data)\n",
        "clear_output\n",
        "print(f'number of english words:{len(vocab_en)},number of german words:{len(vocab_de)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B-LILV_4_C8",
        "outputId": "2c4b86fe-5250-4ece-f3c0-dcaa297fa798"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([('a', 31704),\n",
              "  ('A', 17457),\n",
              "  ('in', 14830),\n",
              "  ('the', 9922),\n",
              "  ('on', 7810),\n",
              "  ('is', 7521),\n",
              "  ('and', 7375),\n",
              "  ('man', 7165),\n",
              "  ('of', 6859),\n",
              "  ('with', 6171),\n",
              "  ('are', 3714),\n",
              "  ('woman', 3652),\n",
              "  ('to', 3123),\n",
              "  ('Two', 3116),\n",
              "  ('at', 2905),\n",
              "  ('wearing', 2616),\n",
              "  ('people', 2348),\n",
              "  ('white', 2104),\n",
              "  ('young', 2055),\n",
              "  ('his', 1969)],\n",
              " [('Ein', 13901),\n",
              "  ('einem', 13697),\n",
              "  ('in', 11829),\n",
              "  ('und', 8925),\n",
              "  ('mit', 8816),\n",
              "  ('auf', 8409),\n",
              "  ('Mann', 7433),\n",
              "  ('einer', 6747),\n",
              "  ('Eine', 5932),\n",
              "  ('ein', 4852),\n",
              "  ('der', 4497),\n",
              "  ('eine', 3972),\n",
              "  ('Frau', 3895),\n",
              "  ('die', 3606),\n",
              "  ('einen', 3479),\n",
              "  ('Zwei', 3175),\n",
              "  ('im', 3079),\n",
              "  ('an', 2569),\n",
              "  ('von', 2360),\n",
              "  ('dem', 2132)])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_en[:20],vocab_de[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikyH_Dro8WU5"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the dataset. We add token [\"\\<bos>\"] at the beginning of the sentence and [\"\\<eos>\"] at the end."
      ],
      "metadata": {
        "id": "iFv5pTyoMl7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1jLu4utDaplR"
      },
      "outputs": [],
      "source": [
        "Batch_size=32\n",
        "max_length=80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "VWNTei4sUNvf"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "import spacy\n",
        "\n",
        "\n",
        "# Load Spacy tokenizers\n",
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "9tvMYXT2YDi9"
      },
      "outputs": [],
      "source": [
        "# Separate yield_tokens functions for German (source) and English (target)\n",
        "def yield_tokens(data_iter, tokenizer, is_source=True):\n",
        "    for src, tgt in data_iter:\n",
        "        if is_source:\n",
        "            yield tokenizer(src)  # German (source)\n",
        "        else:\n",
        "            yield tokenizer(tgt)  # English (target)\n",
        "\n",
        "# Build vocabularies for German (source) and English (target)\n",
        "vocab_de = build_vocab_from_iterator(yield_tokens(train_iter, tokenize_de, is_source=True), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "vocab_en = build_vocab_from_iterator(yield_tokens(train_iter, tokenize_en, is_source=False), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "\n",
        "# Set default index to handle unknown tokens\n",
        "vocab_de.set_default_index(vocab_de[\"<unk>\"])\n",
        "vocab_en.set_default_index(vocab_en[\"<unk>\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "2hrVDndbURVP"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "bos_idx = vocab_de[\"<bos>\"]\n",
        "eos_idx = vocab_de[\"<eos>\"]\n",
        "pad_idx = vocab_de[\"<pad>\"]\n",
        "\n",
        "def preprocess_sentence(sentence, vocab, tokenizer):\n",
        "    tokens = tokenizer(sentence)\n",
        "    tokens = [vocab['<bos>']] + [vocab[token] for token in tokens] + [vocab['<eos>']]\n",
        "    if len(tokens) > max_length:\n",
        "      tokens = tokens[:max_length-1] + [vocab['<eos>']]\n",
        "    else:\n",
        "      tokens += [vocab['<pad>']] * (max_length - len(tokens))\n",
        "    return torch.tensor(tokens, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "      src_batch.append(preprocess_sentence(src_sample, vocab_de, tokenize_de))\n",
        "      tgt_batch.append(preprocess_sentence(tgt_sample, vocab_en, tokenize_en))\n",
        "    src_batch = torch.stack(src_batch)\n",
        "    tgt_batch = torch.stack(tgt_batch)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(list(train_iter), batch_size=32, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(list(valid_iter), batch_size=32, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAHFNX3Rx65T"
      },
      "source": [
        "# GPT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1llEzjdy0GZQ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W60KdCuO0I0M"
      },
      "outputs": [],
      "source": [
        "n_embd=512\n",
        "n_head= 8\n",
        "n_layers= 6\n",
        "dropout= 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VW2KcKQev2H"
      },
      "outputs": [],
      "source": [
        "class maskless_head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.head_size= head_size\n",
        "    self.key=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.query=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.value=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.softmax=nn.Softmax(dim=-1)\n",
        "    self.dropout= nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    k=self.key(x) # b,T,N\n",
        "    q=self.query(x) # b,T,N\n",
        "    v=self.value(x) # b,T,N\n",
        "    k = k.transpose(-2, -1)  # b,N,T\n",
        "    wei= q @ k * self.head_size**-0.5 # b,T,T\n",
        "    wei=self.softmax(wei)\n",
        "    wei = self.dropout(wei)\n",
        "    return wei @ v # b,T,N\n",
        "\n",
        "class masked_head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(max_length, max_length)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class maskless_cross_head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.head_size= head_size\n",
        "    self.key=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.query=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.value=nn.Linear(n_embd,head_size,bias=False)\n",
        "    self.softmax=nn.Softmax(dim=-1)\n",
        "    self.dropout= nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x,y):\n",
        "    k=self.key(y) # b,T,N\n",
        "    q=self.query(x) # b,T,N\n",
        "    v=self.value(y) # b,T,N\n",
        "    k = k.transpose(-2, -1) * self.head_size**-0.5 # b,N,T\n",
        "    wei= q @ k # b,T,T\n",
        "    wei=self.softmax(wei)\n",
        "    wei = self.dropout(wei)\n",
        "    return wei @ v # b,T,N\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, n_embd):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "    nn.Linear(n_embd, 4 * n_embd),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4 * n_embd, n_embd),\n",
        "    nn.Dropout(dropout),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTGi9-tO3pTl"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, head_size, masked='True'):\n",
        "    super().__init__()\n",
        "    if masked=='True':\n",
        "      self.heads = nn.ModuleList([masked_head(head_size) for _ in range(num_heads)])\n",
        "    elif masked=='cross':\n",
        "      self.heads = nn.ModuleList([maskless_cross_head(head_size) for _ in range(num_heads)])\n",
        "    else:\n",
        "      self.heads = nn.ModuleList([maskless_head(head_size) for _ in range(num_heads)])\n",
        "    self.proj = nn.Linear(n_embd, n_embd)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x,y=None):\n",
        "    if y is not None:\n",
        "      out = torch.cat([h(x,y) for h in self.heads], dim=-1)\n",
        "    else:\n",
        "      out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVYhIBeK2dl8"
      },
      "outputs": [],
      "source": [
        "class encoder_block(nn.Module):\n",
        "  def __init__(self, n_embd, n_head):\n",
        "    # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "    super().__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size,masked='False')\n",
        "    self.ffwd = FeedForward(n_embd)\n",
        "    self.ln1 = nn.LayerNorm(n_embd)\n",
        "    self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x\n",
        "\n",
        "class decoder_block(nn.Module):\n",
        "  def __init__(self, n_embd, n_head):\n",
        "    # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "    super().__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size,masked='False')\n",
        "    self.ca = MultiHeadAttention(n_head, head_size,masked='cross')\n",
        "    self.ffwd = FeedForward(n_embd)\n",
        "    self.ln1 = nn.LayerNorm(n_embd)\n",
        "    self.ln2 = nn.LayerNorm(n_embd)\n",
        "    self.ln3 = nn.LayerNorm(n_embd)\n",
        "  def forward(self, x,encoder_output):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x=  x + self.ca(self.ln2(x),encoder_output)\n",
        "    x = x + self.ffwd(self.ln3(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBiQNYNBu11E"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, model_dimension, dropout_probability, expected_max_sequence_length=max_length):\n",
        "      super().__init__()\n",
        "      self.dropout = nn.Dropout(p=dropout_probability)\n",
        "      position_id = torch.arange(0, expected_max_sequence_length).unsqueeze(1)\n",
        "      frequencies = torch.pow(10000., -torch.arange(0, model_dimension, 2, dtype=torch.float) / model_dimension)\n",
        "\n",
        "      positional_encodings_table = torch.zeros(expected_max_sequence_length, model_dimension)\n",
        "      positional_encodings_table[:, 0::2] = torch.sin(position_id * frequencies)  # sine on even positions\n",
        "      positional_encodings_table[:, 1::2] = torch.cos(position_id * frequencies)  # cosine on odd positions\n",
        "      self.register_buffer('positional_encodings_table', positional_encodings_table)\n",
        "\n",
        "  def forward(self, embeddings_batch):\n",
        "      assert embeddings_batch.ndim == 3 and embeddings_batch.shape[-1] == self.positional_encodings_table.shape[1], \\\n",
        "          f'Expected (batch size, max token sequence length, model dimension) got {embeddings_batch.shape}'\n",
        "\n",
        "      positional_encodings = self.positional_encodings_table[:embeddings_batch.shape[1]]\n",
        "      return self.dropout(embeddings_batch + positional_encodings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJCVtwCPwirJ"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, n_embd, n_head, n_layers, max_length, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.encoding= nn.Embedding(len(vocab_de),n_embd)\n",
        "    self.decoding= nn.Embedding(len(vocab_en),n_embd)\n",
        "    self.encoder = nn.ModuleList([encoder_block(n_embd, n_head) for _ in range(n_layers)])\n",
        "    self.decoder = nn.ModuleList([decoder_block(n_embd, n_head) for _ in range(n_layers)])\n",
        "    self.src_pos_embedding = PositionalEncoding(n_embd, dropout)\n",
        "    self.trg_pos_embedding = PositionalEncoding(n_embd, dropout)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc_out = nn.Linear(n_embd, len(vocab_en))\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "    self.init_weights()\n",
        "  def init_weights(self):\n",
        "    for p in self.parameters():\n",
        "      if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    x = self.encoding(x)\n",
        "    y = self.decoding(y)\n",
        "    x = self.src_pos_embedding(x)\n",
        "    y = self.trg_pos_embedding(y)\n",
        "\n",
        "    for enc_block in self.encoder:\n",
        "        x = enc_block(x)\n",
        "    # Decoder\n",
        "    for dec_block in self.decoder:\n",
        "        y = dec_block(y, x)\n",
        "\n",
        "    # Final linear layer\n",
        "    out = self.fc_out(y)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcrwWGMVfe77"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZaFnqjUjnEH"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model= Transformer(n_embd,n_head,n_layers,max_length)\n",
        "model.to(device)\n",
        "optimizer= torch.optim.Adam(model.parameters(),lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPJxtBLgS8Jv"
      },
      "outputs": [],
      "source": [
        "loss_fn  = torch.nn.CrossEntropyLoss()\n",
        "epochs=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjwUDth-g_UX"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/model_checkpoints'\n",
        "checkpoint_file = f'{save_path}/model_checkpoint.pt'\n",
        "if os.path.exists(checkpoint_file):\n",
        "  os.remove(checkpoint_file)\n",
        "torch.save(model.state_dict(), checkpoint_file)\n",
        "for epoch in range(epochs):\n",
        "  model.train()  # Set model to training mode\n",
        "  total_loss = 0\n",
        "  for batch, (src, tgt) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    src, tgt = src.to(device), tgt.to(device)  # Move data to GPU if available\n",
        "\n",
        "    # Forward pass through the model\n",
        "    logits = model(src, tgt)\n",
        "    logits = logits.view(-1, logits.size(-1))\n",
        "\n",
        "    # Flatten target to [batch_size * sequence_length]\n",
        "    tgt = tgt.view(-1)\n",
        "\n",
        "    loss = loss_fn(logits, tgt)\n",
        "\n",
        "    # Backpropagation and optimization step\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "    loss.backward()        # Compute gradients\n",
        "    optimizer.step()       # Update weights\n",
        "\n",
        "    # Accumulate total loss for reporting\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    # Epoch-level reporting\n",
        "    print(f'Epoch {epoch+1}: Batch= {batch} Loss: {(loss.item()):.4f}')\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  print(f'Epoch {epoch+1}: Loss: {avg_loss:.4f}')\n",
        "  if os.path.exists(checkpoint_file):\n",
        "    os.remove(checkpoint_file)\n",
        "  torch.save(model.state_dict(), checkpoint_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0cwFlkgyCrj"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqdHFt6oG3ls",
        "outputId": "e0a65d41-1fed-4d3f-b977-e0b6853b9c26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_path = '/content/drive/MyDrive/model_checkpoints'\n",
        "checkpoint_file = f'{save_path}/model_checkpoint.pt'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model= Transformer(n_embd,n_head,n_layers,max_length)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(checkpoint_file,map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx-3JbU10sLH"
      },
      "outputs": [],
      "source": [
        "k='Hey Alter, wie geht es dir? '\n",
        "k=preprocess_sentence(k, vocab_de, tokenize_de).unsqueeze(0).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOyQPiZw1zqF"
      },
      "outputs": [],
      "source": [
        "start_token=vocab_de[\"<bos>\"]\n",
        "end_token = vocab_de[\"<eos>\"]\n",
        "def generate(model, src, start_token, max_len, device):\n",
        "    model.eval()\n",
        "    src = src.to(device)\n",
        "    target = torch.tensor([[start_token]], device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for _ in range(max_len):\n",
        "        # Pass the source and current target through the model\n",
        "        logits = model(src, target)\n",
        "        # Get the predicted next token (highest probability)\n",
        "        next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
        "\n",
        "        # Append the predicted token to the target sequence\n",
        "        target = torch.cat([target, next_token], dim=1)\n",
        "\n",
        "        # Stop if end token is generated\n",
        "        if next_token.item() == end_token:\n",
        "          break\n",
        "    return target\n",
        "\n",
        "target_sequence = generate(model, k, start_token, max_length, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U22xxnxyAYS"
      },
      "outputs": [],
      "source": [
        "with model.eval():  # Set model to training mode\n",
        "  total_loss = 0\n",
        "  for batch, (src, tgt) in enumerate(valid_loader):\n",
        "    optimizer.zero_grad()\n",
        "    src, tgt = src.to(device), tgt.to(device)  # Move data to GPU if available\n",
        "\n",
        "    # Forward pass through the model\n",
        "    logits = model(src, tgt)\n",
        "    logits = logits.view(-1, logits.size(-1))\n",
        "\n",
        "    # Flatten target to [batch_size * sequence_length]\n",
        "    tgt = tgt.view(-1)\n",
        "\n",
        "    loss = loss_fn(logits, tgt)\n",
        "\n",
        "    # Accumulate total loss for reporting\n",
        "    total_loss += loss.item()\n",
        "    # Epoch-level reporting\n",
        "    print(f' Batch= {batch} Loss: {(loss.item()):.4f}')\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  print(f'Total Avg_loss =Loss: {avg_loss:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}